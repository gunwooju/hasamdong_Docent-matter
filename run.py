import gradio as gr
import pandas as pd
import embedding
import json
import os
import random
import base64
import re
import speech_recognition as sr
from pydub import AudioSegment
from pydub.effects import normalize
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain.schema import AIMessage, HumanMessage
from langchain_upstage import ChatUpstage
from tools import similar_art_search, qa_with_explain, empathize_with_user, normal_chat, wiki_search, archiving
from langchain_core.output_parsers import StrOutputParser
from gtts import gTTS
import tempfile


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ChatUpstage ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatUpstage(streaming=True)

# ì‚¬ìš©í•  ë„êµ¬ ëª©ë¡ ì •ì˜
tools = [similar_art_search, qa_with_explain, empathize_with_user, normal_chat, wiki_search, archiving]
llm_with_tools = llm.bind_tools(tools)

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
bokcheon_df = pd.read_csv("data/bokcheon_museum.csv")
tal_df = pd.read_csv("data/tal_museum.csv")

# ì¶œì²˜ ì»¬ëŸ¼ ì¶”ê°€
bokcheon_df['source'] = 'bokcheon'
tal_df['source'] = 'tal'

# DB ë° Retrieval ë¶ˆëŸ¬ì˜¤ê¸°
searching_bokcheon = embedding.Search(bokcheon_df)
searching_tal = embedding.Search(tal_df)

def convert_to_wav(m4a_file_path):
    """M4A íŒŒì¼ì„ WAVë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    audio = AudioSegment.from_file(m4a_file_path, format="m4a")
    wav_file_path = m4a_file_path.replace(".m4a", ".wav")
    audio.export(wav_file_path, format="wav")
    return wav_file_path

def reduce_noise(audio_file_path):
    """ì†ŒìŒì„ ì¤„ì´ê³  ì˜¤ë””ì˜¤ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    audio = AudioSegment.from_file(audio_file_path, format="wav")
    normalized_audio = normalize(audio)
    normalized_audio.export(audio_file_path, format="wav")

def transcribe_audio(audio_file_path, chunk_length=60000):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not audio_file_path:
        return "[ìŒì„± íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.]"
    
    recognizer = sr.Recognizer()
    
    if audio_file_path.endswith('.m4a'):
        audio_file_path = convert_to_wav(audio_file_path)
    
    reduce_noise(audio_file_path)
    
    audio = AudioSegment.from_file(audio_file_path, format="wav")
    
    if len(audio) < 1000:
        return "[ìŒì„± íŒŒì¼ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 1ì´ˆ ì´ìƒì˜ íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.]"
    elif len(audio) > 600000:
        return "[ìŒì„± íŒŒì¼ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ìµœëŒ€ 10ë¶„ ì´í•˜ì˜ íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.]"
    
    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]
    full_text = ""
    
    for i, chunk in enumerate(chunks):
        if len(chunk) < 1000:
            continue
        
        chunk_file_path = f"chunk_{i}.wav"
        chunk.export(chunk_file_path, format="wav")
        
        with sr.AudioFile(chunk_file_path) as source:
            audio_data = recognizer.record(source)
        
        try:
            text = recognizer.recognize_google(audio_data, language='ko-KR')
            full_text += text + " "
        except sr.UnknownValueError:
            full_text += "[ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.] "
        except sr.RequestError as e:
            full_text += f"[ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—ëŸ¬: {e}] "
        finally:
            os.remove(chunk_file_path)
    
    if audio_file_path.endswith('.wav'):
        os.remove(audio_file_path)
    
    return full_text

def handle_audio(file, history, cur_art):
    if not file:
        return "", history, cur_art
     
    text = transcribe_audio(file)
    if text is None:
        text = "[ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.]"
    
    updated_history = chat(history + [[text, None]], cur_art)
    return "", updated_history, cur_art

def get_image_path(row):
    """ê° ì‘í’ˆì˜ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if row['source'] == 'bokcheon':
        base_path = "data/bok_images"
    else:
        base_path = "data/tal_images"
    
    image_number = str(row['ì´ë¯¸ì§€']).split('.')[0]
    
    extensions = ['.jpg', '.jpeg', '.png', '.gif']
    
    for ext in extensions:
        full_path = os.path.join(base_path, f"{image_number}{ext}")
        if os.path.exists(full_path):
            print(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {full_path}")
            return full_path
    
    print(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {row['ìœ ë¬¼ëª…'] if 'ìœ ë¬¼ëª…' in row else row['ì‘í’ˆëª…']} (ë²ˆí˜¸: {image_number})")
    print(f"í™•ì¸í•œ ê²½ë¡œ: {[os.path.join(base_path, f'{image_number}{ext}') for ext in extensions]}")
    return None

def convert_base64(image_path):
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜"""
    if image_path and os.path.exists(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")
    return None

def get_all_artworks():
    """ëª¨ë“  ì‘í’ˆ ëª©ë¡ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    bokcheon_list = [f"{row['ìœ ë¬¼ëª…']} ({row['ì‹œëŒ€']})" for _, row in bokcheon_df.iterrows()]
    tal_list = [f"{row['ì‘í’ˆëª…']} ({row['ì œì‘ë…„ë„']})" for _, row in tal_df.iterrows()]
    all_list = bokcheon_list + tal_list
    
    search_dict = {}
    for idx, item in enumerate(all_list):
        if idx < len(bokcheon_list):
            search_dict[item] = {'index': bokcheon_df.iloc[idx]['ë²ˆí˜¸'], 'source': 'bokcheon'}
        else:
            search_dict[item] = {'index': tal_df.iloc[idx - len(bokcheon_list)]['ë²ˆí˜¸'], 'source': 'tal'}
    
    return all_list, json.dumps(search_dict, ensure_ascii=False)

def search_art(query, selected_museum):
    """ì„ íƒëœ ë°•ë¬¼ê´€ì—ì„œ ì‘í’ˆì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜"""
    if selected_museum == "ë³µì²œ ë°•ë¬¼ê´€":
        results = searching_bokcheon.search(query, searching_bokcheon.retriever_full)
    elif selected_museum == "íƒˆ ë°•ë¬¼ê´€":
        results = searching_tal.search(query, searching_tal.retriever_full)
    else:
        results_bokcheon = searching_bokcheon.search(query, searching_bokcheon.retriever_full)
        results_tal = searching_tal.search(query, searching_tal.retriever_full)
        results = results_bokcheon + results_tal
    
    search_list = []
    search_dict = {}
    
    for result in results:
        element = f"{result.metadata['title']} ({result.metadata['year']})"
        search_list.append(element)
        search_dict[element] = result.metadata
        search_dict[element]['source'] = 'bokcheon' if selected_museum == "ë³µì²œ ë°•ë¬¼ê´€" or (selected_museum == "ëª¨ë‘" and result in results_bokcheon) else 'tal'
    
    return gr.update(choices=search_list, value=None), json.dumps(search_dict, ensure_ascii=False)

def text_to_speech(text):
    try:
        tts = gTTS(text=text, lang='ko')
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
            tts.save(fp.name)
            return fp.name
    except Exception as e:
        print(f"TTS ì—ëŸ¬: {str(e)}")
        return None

def dropdown_change(item, search_dict, is_child, generate_audio):
    if item:
        search_dict = json.loads(search_dict)
        if search_dict[item].get('source') == 'bokcheon':
            search_art = bokcheon_df[bokcheon_df['ë²ˆí˜¸'].astype(str) == str(search_dict[item]['index'])]
        else:
            search_art = tal_df[tal_df['ë²ˆí˜¸'].astype(str) == str(search_dict[item]['index'])]
        
        if search_art.empty:
            print(f"ì‘í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {item}")
            return None, None, "ì‘í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None, gr.update(visible=False, value=None)

        search_art = search_art.iloc[0]
        
        image_path = get_image_path(search_art)
        if image_path:
            if search_dict[item].get('source') == 'bokcheon':
                description = search_art['ì–´ë¦°ì´ ì „ìš©'] if is_child else search_art['ì‘í’ˆ ì„¤ëª…']
            else:
                description = search_art['ì–´ë¦°ì•„ì´'] if is_child else search_art['ì‘í’ˆì„¤ëª…']
            
            audio_path = None
            if generate_audio:
                audio_path = text_to_speech(description)
                if audio_path is None:
                    print("ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            return image_path, search_art.to_json(force_ascii=False), description, audio_path, gr.update(visible=generate_audio, value=audio_path)
        else:
            return None, search_art.to_json(force_ascii=False), "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None, gr.update(visible=False, value=None)
    else:
        return None, None, None, None, gr.update(visible=False, value=None)
def user(user_message, history, cur_art):
    """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    return "", history + [[user_message, None]], cur_art

def chat(history, cur_art):
    """AIì™€ì˜ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    if not history:
        history = []

    # Extract the last message from history
    message = history[-1][0] if history else ""

    # Check if the message is empty
    if not message.strip():
        print("Error: Message is empty.")
        return history

    # Load current artwork information
    cur_art = cur_art if isinstance(cur_art, str) else cur_art.value if hasattr(cur_art, 'value') else "{}"
    cur_art = json.loads(cur_art) if cur_art else {}

    basic_prompt = f"""
    ## Role: ë°•ë¬¼ê´€ ë„ìŠ¨íŠ¸

    ## Instruction
    - ì£¼ì–´ì§„ ì‘í’ˆ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì™€ ëŒ€í™”í•©ë‹ˆë‹¤.
    - ì‘í’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
    - íƒˆ ë°•ë¬¼ê´€ì˜ ì‘í’ˆì¼ ê²½ìš°, íƒˆì˜ íŠ¹ì§•ê³¼ ì˜ë¯¸ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

    ## í˜„ì¬ ì‘í’ˆ ì •ë³´
    ìœ ë¬¼ëª…/ì‘í’ˆëª…: {cur_art.get('ìœ ë¬¼ëª…') or cur_art.get('ì‘í’ˆëª…')}
    ì‹œëŒ€/ì œì‘ë…„ë„: {cur_art.get('ì‹œëŒ€') or cur_art.get('ì œì‘ë…„ë„')}
    ë°œêµ´ ì¥ì†Œ/ì¬ë£Œ: {cur_art.get('ë°œêµ´ ì¥ì†Œ') or cur_art.get('ì¬ë£Œ', 'ì •ë³´ ì—†ìŒ')}
    ê·œê²©: {cur_art.get('ê·œê²©', 'ì •ë³´ ì—†ìŒ')}
    ì‘í’ˆ ì„¤ëª…: {cur_art.get('ì‘í’ˆ ì„¤ëª…') or cur_art.get('ì‘í’ˆì„¤ëª…')}
    ê°„ë‹¨ ìš”ì•½: {cur_art.get('ê°„ë‹¨ ìš”ì•½') or cur_art.get('ê°„ë‹¨ìš”ì•½', 'ì •ë³´ ì—†ìŒ')}
    ì–´ë¦°ì´ ì „ìš©: {cur_art.get('ì–´ë¦°ì´ ì „ìš©') or cur_art.get('ì–´ë¦°ì•„ì´', 'ì •ë³´ ì—†ìŒ')}
    ë°•ë¬¼ê´€ ì¶œì²˜: {'íƒˆ ë°•ë¬¼ê´€' if cur_art.get('source') == 'tal' else 'ë³µì²œ ë°•ë¬¼ê´€'}
    """

    chat_with_history_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", basic_prompt),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{message}"),
        ]
    )

    chain = chat_with_history_prompt | llm | StrOutputParser()

    history_langchain_format = [AIMessage(content=basic_prompt)]
    for human, ai in history[:-1]:
        history_langchain_format.append(HumanMessage(content=human))
        if ai:
            history_langchain_format.append(AIMessage(content=ai))

    # Use RAG if applicable, otherwise continue with the normal process
    output = tool_rag(message, history, cur_art)
    if output:
        generator = chain.stream({"message": output['prompt'], "history": history_langchain_format})
    else:
        generator = chain.stream({"message": message, "history": history_langchain_format})

    response = ""
    for gen in generator:
        response += gen

    history[-1] = (message, response)
    return history


def tool_rag(question, history, cur_art):
    """RAG (Retrieval-Augmented Generation) ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜"""
    output = {}
    tool_calls = llm_with_tools.invoke(question).tool_calls
    if not tool_calls:
        return None
    context = ""
    for tool_call in tool_calls:
        tool_output = call_tool_func(tool_call, question)
        context, tool_name = tool_output
        context += str(context).strip()
        tool_name = str(tool_name)
    output['tool_name'] = tool_name

    if tool_name == "qa_with_explain":
        prompt = f"""
## Role: ë°•ë¬¼ê´€ ë„ìŠ¨íŠ¸

## Instruction
- ë°•ë¬¼ê´€ ë„ìŠ¨íŠ¸ë¡œì„œ ì£¼ì–´ì§„ ## ì‘í’ˆ ì •ë³´ ## ë¥¼ ì½ê³  ìƒëŒ€ë°©ì—ê²Œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
- ì‘í’ˆì— ëŒ€í•œ ì„¤ëª…ì„ ìš”êµ¬í•  ê²½ìš° ì „ë°˜ì ì¸ ì‘í’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œê¸° ì‰½ê²Œ í’€ì–´ì„œ ì „ë‹¬í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ì´ êµ¬ì²´ì ì¸ ê²½ìš° ì‘í’ˆì˜ ì •ë³´ë¥¼ ì°¸ê³ í•´ ê°„ë‹¨í•˜ê³  ëª…ë£Œí•˜ê²Œ ëŒ€ë‹µí•©ë‹ˆë‹¤.
- historyë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
- ì¹œì ˆí•˜ê³  ìƒëƒ¥í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
- í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
- {cur_art.get('ìœ ë¬¼ëª…') or cur_art.get('ì‘í’ˆëª…')}ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
- íƒˆ ë°•ë¬¼ê´€ì˜ ì‘í’ˆì¼ ê²½ìš°, íƒˆì˜ íŠ¹ì§•, ìš©ë„, ë¬¸í™”ì  ì˜ë¯¸ ë“±ì„ ì„¤ëª…ì— í¬í•¨í•©ë‹ˆë‹¤.

## ì‘í’ˆ ì •ë³´
ìœ ë¬¼ëª…/ì‘í’ˆëª…: {cur_art.get('ìœ ë¬¼ëª…') or cur_art.get('ì‘í’ˆëª…')}
ì‹œëŒ€/ì œì‘ë…„ë„: {cur_art.get('ì‹œëŒ€') or cur_art.get('ì œì‘ë…„ë„')}
ë°œêµ´ ì¥ì†Œ/ì¬ë£Œ: {cur_art.get('ë°œêµ´ ì¥ì†Œ') or cur_art.get('ì¬ë£Œ', 'ì •ë³´ ì—†ìŒ')}
ê·œê²©: {cur_art.get('ê·œê²©', 'ì •ë³´ ì—†ìŒ')}
ì‘í’ˆ ì„¤ëª…: {cur_art.get('ì‘í’ˆ ì„¤ëª…') or cur_art.get('ì‘í’ˆì„¤ëª…')}
ê°„ë‹¨ ìš”ì•½: {cur_art.get('ê°„ë‹¨ ìš”ì•½') or cur_art.get('ê°„ë‹¨ìš”ì•½', 'ì •ë³´ ì—†ìŒ')}
ì–´ë¦°ì´ ì „ìš©: {cur_art.get('ì–´ë¦°ì´ ì „ìš©') or cur_art.get('ì–´ë¦°ì•„ì´', 'ì •ë³´ ì—†ìŒ')}
ë°•ë¬¼ê´€ ì¶œì²˜: {'íƒˆ ë°•ë¬¼ê´€' if cur_art.get('source') == 'tal' else 'ë³µì²œ ë°•ë¬¼ê´€'}

## ì§ˆë¬¸
{question}
"""
        output['prompt'] = prompt
        return output
    
    return None

def call_tool_func(tool_call, question):
    """íŠ¹ì • ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    tool_name = tool_call["name"].lower()
    if tool_name not in globals():
        print("Tool not found", tool_name)
        return None
    selected_tool = globals()[tool_name]
    print(tool_call)

    if "query" not in tool_call["args"]:
        tool_call["args"] = {"query": question}
        print("query is empty", tool_call)

    return selected_tool.invoke(tool_call["args"]), tool_name

# Gradio ì¸í„°í˜ì´ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜
css = """
#chat_img img {width: 600px; height: 600px; align-items: center;}
#chat_img Column {align-items: center;}
"""
# ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì§€ì •
IMAGE_PATH = "C:\ë¹„ì „ê³µì í•˜ì‚¼ë™\chatbot(upstagever)\data\dosent pictures.webp" # ì—¬ê¸°ì— ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”

# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±
with gr.Blocks(title="ë°•ë¬¼ê´€ AI ê°€ì´ë“œ", css=css, theme=gr.themes.Soft()) as demo:
    gr.Markdown("<h1 style='text-align: center; margin-bottom: 1rem'>ë°•ë¬¼ê´€ AI ê°€ì´ë“œ</h1>")
    
    with gr.Row():
        search_art_tb = gr.Textbox(label="ê²€ìƒ‰", info="ì‘í’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        museum_select = gr.Radio(["ë³µì²œ ë°•ë¬¼ê´€", "íƒˆ ë°•ë¬¼ê´€", "ëª¨ë‘"], label="ë°•ë¬¼ê´€ ì„ íƒ", value="ëª¨ë‘")
        
        # ê³ ì •ëœ ê²½ë¡œì˜ webp ì´ë¯¸ì§€ë¥¼ í‘œì‹œ
        user_image = gr.Image(value=IMAGE_PATH, width=400, height=400)
    
    initial_list, initial_dict = get_all_artworks()
    search_dropdown = gr.Dropdown(choices=initial_list, value='', label="ì‘í’ˆ ëª©ë¡", info="ì‘í’ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”.", interactive=True, filterable=True)
    search_btn = gr.Button("ê²€ìƒ‰")
    search_to_meta = gr.Textbox(value=initial_dict, visible=False)
    cur_search_art_tb = gr.Textbox(label="search_art_tb", visible=False)

    is_child = gr.Checkbox(label="ì–´ë¦°ì´ìš© ì„¤ëª…", value=False)

    with gr.Row() as art_info:
        with gr.Column(scale=1):
            art_image = gr.Image(value=None, label="ì‘í’ˆ ì´ë¯¸ì§€", scale=1, height=400, width=400)
        with gr.Column(scale=2):
            art_description = gr.Textbox(label="ì‘í’ˆ ì„¤ëª…", lines=10)
            generate_audio_checkbox = gr.Checkbox(label="ìŒì„±ìœ¼ë¡œ ë“£ê¸°", value=False)
            audio_player = gr.Audio(label="ìŒì„±", visible=False, autoplay=True)

    # ChatBot
    with gr.Row() as art_chatbot:
        with gr.Column(scale=1.2):
            gr.Markdown("<h2 style='text-align: center; margin-bottom: 1rem'>AI ë„ìŠ¨íŠ¸</h2>")
            gr.Markdown("<p style='text-align: center; font-size: 14px; margin-bottom: 1rem'>ì‘í’ˆì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆë‚˜ìš” ? ğŸ‘€ </p>")
            
            custom_art_chatbot = gr.Chatbot(height=600)
            msg = gr.Textbox()
            audio = gr.Audio(type="filepath")
            clear = gr.ClearButton([msg, custom_art_chatbot])

            # ìŒì„± ì…ë ¥ ì²˜ë¦¬
            audio.change(handle_audio, [audio, custom_art_chatbot, cur_search_art_tb], [msg, custom_art_chatbot, cur_search_art_tb])
            msg.submit(user, [msg, custom_art_chatbot, cur_search_art_tb], [msg, custom_art_chatbot], queue=False).then(
                chat, [custom_art_chatbot, cur_search_art_tb], [custom_art_chatbot])
            clear.click(lambda: None, None, custom_art_chatbot, queue=False)

    search_art_tb.submit(search_art, [search_art_tb, museum_select], [search_dropdown, search_to_meta], queue=False)
    
    search_btn.click(
        fn=search_art, 
        inputs=[search_art_tb, museum_select],
        outputs=[search_dropdown, search_to_meta]
    )
    
    search_dropdown.change(
        fn=dropdown_change, 
        inputs=[search_dropdown, search_to_meta, is_child, generate_audio_checkbox], 
        outputs=[art_image, cur_search_art_tb, art_description, audio_player, audio_player]
    )

    is_child.change(
        fn=dropdown_change,
        inputs=[search_dropdown, search_to_meta, is_child, generate_audio_checkbox],
        outputs=[art_image, cur_search_art_tb, art_description, audio_player, audio_player]
    )
    def update_audio_visibility(generate_audio):
        return gr.update(visible=generate_audio)
    
    generate_audio_checkbox.change(
        fn=update_audio_visibility,
        inputs=[generate_audio_checkbox],
        outputs=[audio_player]
    ).then(
        fn=dropdown_change,
        inputs=[search_dropdown, search_to_meta, is_child, generate_audio_checkbox],
        outputs=[art_image, cur_search_art_tb, art_description, audio_player, audio_player]
    )


# Gradio ì•± ì‹¤í–‰
demo.launch(share=True)
